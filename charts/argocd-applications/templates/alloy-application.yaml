apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: alloy
spec:
  project: '{{ required ".Values.cluster_name is required" .Values.cluster_name }}'
  source:
    repoURL: https://grafana.github.io/helm-charts
    targetRevision: "3.7.1"
    chart: k8s-monitoring
    helm:
      valuesObject:
        vault_name: '{{ required ".Values.vault_name is required" .Values.vault_name }}'
        cluster_name: '{{ required ".Values.cluster_name is required" .Values.cluster_name }}'
        global:
          extraEnv:
            - name: SSL_CERT_FILE
              value: /etc/ssl/certs/ca-certificates.crt
          extraVolumes:
            - name: ca-certificates
              configMap:
                name: trust-bundle
          extraVolumeMounts:
            - name: ca-certificates
              mountPath: /etc/ssl/certs
              readOnly: true
        cluster:
          name: '{{ required ".Values.cluster_name is required" .Values.cluster_name }}'

        destinations:
          - name: localMimir
            type: prometheus
            url: http://mimir-gateway.mimir.svc/api/v1/push
            tenantId: '{{ required ".Values.cluster_name is required" .Values.cluster_name }}'
            secret:
              # This is just the tenant name
              create: false
              embed: true
          - name: localLoki
            type: loki
            url: http://loki.loki.svc:3100/loki/api/v1/push
            tenantId: '{{ required ".Values.cluster_name is required" .Values.cluster_name }}'
            secret:
              # This is just the tenant name
              create: false
              embed: true

        extraObjects:
          - apiVersion: monitoring.coreos.com/v1
            kind: Probe
            metadata:
              name: hubitat-http
              namespace: "alloy"
            spec:
              interval: 30s
              module: http_2xx
              prober:
                url: alloy-alloy-metrics-cluster.alloy.svc:12345
                path: /api/v0/component/prometheus.exporter.blackbox.blackbox_exporter/probe
              targets:
                staticConfig:
                  static:
                    - http://hubitat.local.symmatree.com
          - apiVersion: monitoring.coreos.com/v1
            kind: Probe
            metadata:
              name: raconteur-syno-ui
              namespace: "alloy"
            spec:
              interval: 30s
              module: http_2xx
              prober:
                url: alloy-alloy-metrics-cluster.alloy.svc:12345
                path: /api/v0/component/prometheus.exporter.blackbox.blackbox_exporter/probe
              targets:
                staticConfig:
                  static:
                    - https://raconteur.ad.local.symmatree.com:5001/
          - apiVersion: monitoring.coreos.com/v1
            kind: Probe
            metadata:
              name: morpheus-ui
              namespace: "alloy"
            spec:
              interval: 30s
              module: http_2xx
              prober:
                url: alloy-alloy-metrics-cluster.alloy.svc:12345
                path: /api/v0/component/prometheus.exporter.blackbox.blackbox_exporter/probe
              targets:
                staticConfig:
                  static:
                    - https://morpheus.local.symmatree.com/
          - apiVersion: networking.k8s.io/v1
            kind: Ingress
            metadata:
              name: otlp-ingress
              namespace: "alloy"
              annotations:
                cert-manager.io/cluster-issuer: real-cert
                external-dns.alpha.kubernetes.io/hostname: 'otlp.{{ required ".Values.cluster_name is required" .Values.cluster_name }}.symmatree.com'
            spec:
              ingressClassName: cilium
              tls:
                - secretName: otlp-tls
                  hosts:
                    - 'otlp.{{ required ".Values.cluster_name is required" .Values.cluster_name }}.symmatree.com'
              rules:
                - host: 'otlp.{{ required ".Values.cluster_name is required" .Values.cluster_name }}.symmatree.com'
                  http:
                    paths:
                      - path: /
                        pathType: Prefix
                        backend:
                          service:
                            name: alloy-application-observability
                            port:
                              number: 4318
        # https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/charts/feature-cluster-metrics/values.yaml
        clusterMetrics:
          enabled: true
          controlPlane:
            enabled: true
          kubeProxy:
            # there isn't one, cilium replaces it.
            enabled: false
          windows-exporter:
            enabled: false
            deploy: false
          node-exporter:
            enabled: true
            deploy: true
            metricsTuning:
              useDefaultAllowList: true
              useIntegrationAllowList: true
              includeMetrics:
                - "node_pressure.*"
                - "node_xfs.*"
                - "node_time_seconds"
                - "node_bonding.*"
              dropMetricsForFilesystem:
                - ramfs
                - tmpfs
                - nsfs
                - rootfs
                - iso9660
                - overlay
            extraArgs:
              - --collector.filesystem.fs-types-exclude=^(ramfs|tmpfs|nsfs|rootfs|iso9660|overlay)$
          kepler:
            enabled: false
          opencost:
            enabled: false
        clusterEvents:
          enabled: true
          # logfmt version does NO escaping:
          # https://github.com/grafana/alloy/blob/main/internal/component/loki/source/kubernetes_events/event_controller.go#L303
          # to
          # https://github.com/grafana/alloy/blob/main/internal/component/loki/source/kubernetes_events/event_controller.go#L324
          logFormat: json
        nodeLogs:
          # Talos doesn't surface these through the filesystem.
          enabled: false
        podLogs:
          enabled: true
        applicationObservability:
          enabled: true
          receivers:
            otlp:
              # grpc:
              #   enabled: true
              #   port: 4317
              #   includeMetadata: true
              http:
                enabled: true
                port: 4318
                includeMetadata: true
          processors:
            kubernetes_node:
              enabled: true
          # connectors:
          #   spanLogs:
          #     enabled: true
          #     roots: true
          #     spans: false
          #   spanMetrics:
          #     enabled: true
          metrics:
            enabled: true
          logs:
            enabled: true
          traces:
            enabled: false
        prometheusOperatorObjects:
          enabled: true
          crds:
            deploy: false
        alloy-metrics:
          enabled: true
          serviceMonitor:
            enabled: true
          # This is the instance running prometheus.operator.probes
          # so make it also the blackbox exporter.
          # https://github.com/grafana/alloy/issues/2333#issuecomment-2741631302
          # goes a long way here.
          extraConfig: |-
            prometheus.exporter.blackbox "blackbox_exporter" {
              config = "{ modules: { http_2xx: { prober: http, timeout: 5s } } }"
            }
          alloy:
            resources: # Set 2025-07-20
              # requests:
              #   memory: 768Mi
              limits:
                memory: 1Gi
        alloy-singleton:
          extraConfig: |-
            mimir.rules.kubernetes "default" {
              address = "http://mimir-gateway.mimir.svc"
              tenant_id = "{{ required ".Values.cluster_name is required" .Values.cluster_name }}"
            }
          enabled: true
          serviceMonitor:
            enabled: true
          alloy:
            resources: # Set 2025-07-20
              # requests:
              #   memory: 256Mi
              limits:
                memory: 512Mi
        alloy-logs:
          enabled: true
          serviceMonitor:
            enabled: true
          alloy:
            mounts:
              # /var/log/pods and /var/log/containers exist. (Also audit.)
              varlog: true
              dockercontainers: false
        # alloy-receiver:
        #   enabled: true
        #   serviceMonitor:
        #     enabled: true
        #   controller:
        #     type: "deployment"
        #   alloy:
        #     extraPorts:
        #       - name: otlp-grpc
        #         port: 4317
        #         targetPort: 4317
        #         protocol: TCP
        #       - name: otlp-http
        #         port: 4318
        #         targetPort: 4318
        #         protocol: TCP
        integrations:
          alloy:
            instances:
              - name: alloy
                namespace: alloy
                labelSelectors:
                  app.kubernetes.io/name:
                    - alloy-metrics
                    - alloy-singleton
                    - alloy-logs
          cert-manager:
            instances:
              - name: cert-manager
                namespace: cert-manager
                labelSelectors:
                  app.kubernetes.io/name: cert-manager
          # grafana:
          #   instances:
          #     - name: lgtm-grafana
          #       namespace: lgtm
          #       labelSelectors:
          #         app.kubernetes.io/name: grafana
          # loki:
          #   instances:
          #     - name: lgtm-loki
          #       namespace: lgtm
          #       labelSelectors:
          #         app.kubernetes.io/name: loki
          # mimir:
          #   instances:
          #     - name: lgtm-mimir
          #       namespace: lgtm
          #       labelSelectors:
          #         app.kubernetes.io/name: mimir

  destination:
    server: https://kubernetes.default.svc
    namespace: alloy
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/enforce: privileged
        pod-security.kubernetes.io/warn: privileged
        trust-bundle: enabled
