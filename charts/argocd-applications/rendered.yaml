---
# Source: argocd-applications/templates/alloy-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: alloy
spec:
  project: 'placeholder'
  source:
    repoURL: https://grafana.github.io/helm-charts
    targetRevision: "3.7.1"
    chart: k8s-monitoring
    helm:
      valuesObject:
        vault_name: 'placeholder'
        cluster_name: 'placeholder'
        global:
          extraEnv:
            - name: SSL_CERT_FILE
              value: /etc/ssl/certs/ca-certificates.crt
          extraVolumes:
            - name: ca-certificates
              configMap:
                name: trust-bundle
          extraVolumeMounts:
            - name: ca-certificates
              mountPath: /etc/ssl/certs
              readOnly: true
        cluster:
          name: 'placeholder'

        destinations:
          - name: localMimir
            type: prometheus
            url: http://mimir-gateway.mimir.svc/api/v1/push
            tenantId: 'placeholder'
            secret:
              # This is just the tenant name
              create: false
              embed: true
          - name: localLoki
            type: loki
            url: http://loki-gateway.loki.svc/loki/api/v1/push
            tenantId: 'placeholder'
            secret:
              # This is just the tenant name
              create: false
              embed: true

        extraObjects:
          - apiVersion: monitoring.coreos.com/v1
            kind: Probe
            metadata:
              name: hubitat-http
              namespace: "argocd-applications"
            spec:
              interval: 30s
              module: http_2xx
              prober:
                url: alloy-alloy-metrics-cluster.alloy.svc:12345
                path: /api/v0/component/prometheus.exporter.blackbox.blackbox_exporter/probe
              targets:
                staticConfig:
                  static:
                    - http://hubitat.local.symmatree.com
          - apiVersion: monitoring.coreos.com/v1
            kind: Probe
            metadata:
              name: raconteur-syno-ui
              namespace: "argocd-applications"
            spec:
              interval: 30s
              module: http_2xx
              prober:
                url: alloy-alloy-metrics-cluster.alloy.svc:12345
                path: /api/v0/component/prometheus.exporter.blackbox.blackbox_exporter/probe
              targets:
                staticConfig:
                  static:
                    - https://raconteur.ad.local.symmatree.com:5001/
          - apiVersion: monitoring.coreos.com/v1
            kind: Probe
            metadata:
              name: morpheus-ui
              namespace: "argocd-applications"
            spec:
              interval: 30s
              module: http_2xx
              prober:
                url: alloy-alloy-metrics-cluster.alloy.svc:12345
                path: /api/v0/component/prometheus.exporter.blackbox.blackbox_exporter/probe
              targets:
                staticConfig:
                  static:
                    - https://morpheus.local.symmatree.com/
        # https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/charts/feature-cluster-metrics/values.yaml
        clusterMetrics:
          enabled: true
          controlPlane:
            enabled: true
          kubeProxy:
            # there isn't one, cilium replaces it.
            enabled: false
          windows-exporter:
            enabled: false
            deploy: false
          node-exporter:
            enabled: true
            deploy: true
            metricsTuning:
              useDefaultAllowList: true
              useIntegrationAllowList: true
              includeMetrics:
                - "node_pressure.*"
                - "node_xfs.*"
                - "node_time_seconds"
                - "node_bonding.*"
              dropMetricsForFilesystem:
                - ramfs
                - tmpfs
                - nsfs
                - overlayfs
            extraArgs:
              - --collector.filesystem.fs-types-exclude=^(ramfs|tmpfs|nsfs|overlayfs)$
          kepler:
            enabled: false
          opencost:
            enabled: false
        clusterEvents:
          enabled: true
          # logfmt version does NO escaping:
          # https://github.com/grafana/alloy/blob/main/internal/component/loki/source/kubernetes_events/event_controller.go#L303
          # to
          # https://github.com/grafana/alloy/blob/main/internal/component/loki/source/kubernetes_events/event_controller.go#L324
          logFormat: json
        nodeLogs:
          # Talos doesn't surface these through the filesystem.
          enabled: false
        podLogs:
          enabled: true
        # applicationObservability:
        #   enabled: true
        #   receivers:
        #     otlp:
        #       grpc:
        #         enabled: true
        #         port: 4317
        #         includeMetadata: true
        #       http:
        #         enabled: true
        #         port: 4318
        #         includeMetadata: true
        #   processors:
        #     kubernetes_node:
        #       enabled: true
        #   connectors:
        #     spanLogs:
        #       enabled: true
        #       roots: true
        #       spans: false
        #     spanMetrics:
        #       enabled: true
        #   metrics:
        #     enabled: false
        #   logs:
        #     enabled: false
        #   traces:
        #     enabled: true
        prometheusOperatorObjects:
          enabled: true
          crds:
            deploy: false
        alloy-metrics:
          enabled: true
          serviceMonitor:
            enabled: true
          # This is the instance running prometheus.operator.probes
          # so make it also the blackbox exporter.
          # https://github.com/grafana/alloy/issues/2333#issuecomment-2741631302
          # goes a long way here.
          extraConfig: |-
            prometheus.exporter.blackbox "blackbox_exporter" {
              config = "{ modules: { http_2xx: { prober: http, timeout: 5s } } }"
            }
          alloy:
            resources: # Set 2025-07-20
              # requests:
              #   memory: 768Mi
              limits:
                memory: 1Gi
        alloy-singleton:
          extraConfig: |-
            mimir.rules.kubernetes "default" {
              address = "http://mimir-gateway.mimir.svc"
              tenant_id = "placeholder"
            }
          enabled: true
          serviceMonitor:
            enabled: true
          alloy:
            resources: # Set 2025-07-20
              # requests:
              #   memory: 256Mi
              limits:
                memory: 512Mi
        alloy-logs:
          enabled: true
          serviceMonitor:
            enabled: true
          alloy:
            mounts:
              # /var/log/pods and /var/log/containers exist. (Also audit.)
              varlog: true
              dockercontainers: false
        # alloy-receiver:
        #   enabled: true
        #   serviceMonitor:
        #     enabled: true
        #   controller:
        #     type: "deployment"
        #   alloy:
        #     extraPorts:
        #       - name: otlp-grpc
        #         port: 4317
        #         targetPort: 4317
        #         protocol: TCP
        #       - name: otlp-http
        #         port: 4318
        #         targetPort: 4318
        #         protocol: TCP
        integrations:
          alloy:
            instances:
              - name: alloy
                namespace: alloy
                labelSelectors:
                  app.kubernetes.io/name:
                    - alloy-metrics
                    - alloy-singleton
                    - alloy-logs
          cert-manager:
            instances:
              - name: cert-manager
                namespace: cert-manager
                labelSelectors:
                  app.kubernetes.io/name: cert-manager
          # grafana:
          #   instances:
          #     - name: lgtm-grafana
          #       namespace: lgtm
          #       labelSelectors:
          #         app.kubernetes.io/name: grafana
          # loki:
          #   instances:
          #     - name: lgtm-loki
          #       namespace: lgtm
          #       labelSelectors:
          #         app.kubernetes.io/name: loki
          # mimir:
          #   instances:
          #     - name: lgtm-mimir
          #       namespace: lgtm
          #       labelSelectors:
          #         app.kubernetes.io/name: mimir

  destination:
    server: https://kubernetes.default.svc
    namespace: alloy
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/enforce: privileged
        pod-security.kubernetes.io/warn: privileged
        trust-bundle: enabled
---
# Source: argocd-applications/templates/apprise-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: apprise
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: tanka
    plugin:
      env:
        - name: TK_ENV
          value: apprise
      parameters:
        - name: cluster_name
          string: 'placeholder'
        - name: vault_name
          string: 'placeholder'
        - name: project_id
          string: 'placeholder'
        - name: app_settings
          map:
            hostname: 'apprise.placeholder.symmatree.com'
            cluster_issuer: "real-cert"
            apprise_env: 'placeholder-apprise-env'
            apprise_admin: 'placeholder-apprise-admin'
  destination:
    server: https://kubernetes.default.svc
    namespace: apprise
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/warn: baseline
---
# Source: argocd-applications/templates/argocd-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: argocd
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: charts/argocd
    helm:
      valueFiles:
        - values.yaml
      valuesObject:
        targetRevision: 'placeholder'
        cluster_name: 'placeholder'
        vault_name: 'placeholder'
        argo-cd:
          global:
            domain: 'argocd.placeholder.symmatree.com'
          server:
            ingressGrpc:
              hostname: 'grpc-argocd.placeholder.symmatree.com'
  destination:
    server: https://kubernetes.default.svc
    namespace: argocd
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
      - FailOnSharedResource=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/warn: baseline
---
# Source: argocd-applications/templates/argocd-mixin-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: argocd-mixin
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: tanka
    plugin:
      env:
        - name: TK_ENV
          value: argocd-mixin
      parameters:
        - name: cluster_name
          string: 'placeholder'
        - name: vault_name
          string: 'placeholder'
        - name: project_id
          string: 'placeholder'
        - name: app_settings
          map: {}
  destination:
    server: https://kubernetes.default.svc
    namespace: argocd
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - ServerSideApply=true
---
# Source: argocd-applications/templates/cert-manager-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: cert-manager
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: charts/cert-manager
    helm:
      skipCrds: true
      valueFiles:
        - values.yaml
      valuesObject:
        cluster_name: 'placeholder'
        project_id: 'placeholder'
        vault_name: 'placeholder'
        trust-manager:
          secretTargets:
            authorizedSecrets:
              - 'placeholder-ca-tls'
  destination:
    server: https://kubernetes.default.svc
    namespace: cert-manager
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/warn: baseline
---
# Source: argocd-applications/templates/cilium-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: cilium
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: charts/cilium
    helm:
      valueFiles:
        - values.yaml
      # Inject values from Terraform or that vary by environment.
      valuesObject:
        cilium:
          ipv4NativeRoutingCIDR: 'placeholder'
          cluster:
            name: 'placeholder'
          hubble:
            tls:
              auto:
                certManagerIssuerRef:
                  name: 'placeholder-ca-issuer'
            ui:
              ingress:
                hosts:
                  - 'hubble.placeholder.symmatree.com'
                tls:
                  - secretName: hubble-ui-tls
                    hosts:
                      - 'hubble.placeholder.symmatree.com'
  destination:
    server: https://kubernetes.default.svc
    namespace: cilium
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/enforce: privileged
        pod-security.kubernetes.io/warn: privileged
---
# Source: argocd-applications/templates/cilium-config-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: cilium-config
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: charts/cilium-config
    helm:
      # Inject values from Terraform or that vary by environment.
      valuesObject:
        external_ip_cidr: 'placeholder'
        targetRevision: 'placeholder'
  destination:
    server: https://kubernetes.default.svc
    namespace: cilium
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/enforce: privileged
        pod-security.kubernetes.io/warn: privileged
---
# Source: argocd-applications/templates/cilium-mixin-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: cilium-mixin
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: tanka
    plugin:
      env:
        - name: TK_ENV
          value: cilium-mixin
      parameters:
        - name: cluster_name
          string: 'placeholder'
        - name: vault_name
          string: 'placeholder'
        - name: project_id
          string: 'placeholder'
        - name: app_settings
          map: {}
  destination:
    server: https://kubernetes.default.svc
    namespace: cilium
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - ServerSideApply=true
---
# Source: argocd-applications/templates/external-dns-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: external-dns
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: charts/external-dns
    helm:
      valueFiles:
        - values.yaml
      valuesObject:
        cluster_name: 'placeholder'
        project_id: 'placeholder'
        vault_name: 'placeholder'
        external-dns:
          txtOwnerId: 'placeholder'
          domainFilters:
            - 'placeholder.symmatree.com'
            - 0.10.in-addr.arpa
          extraArgs:
            - '--google-project=placeholder'
            - '--regex-domain-exclusion=^_acme-challenge\.'
  destination:
    server: https://kubernetes.default.svc
    namespace: external-dns
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/warn: baseline
---
# Source: argocd-applications/templates/grafana-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: grafana
spec:
  project: 'placeholder'
  source:
    repoURL: https://grafana.github.io/helm-charts
    targetRevision: "10.4.2"
    chart: grafana
    helm:
      valuesObject:
        vault_name: 'placeholder'
        cluster_name: 'placeholder'
        global:
          extraEnv:
            - name: SSL_CERT_FILE
              value: /etc/ssl/certs/ca-certificates.crt
          extraVolumes:
            - name: ca-certificates
              configMap:
                name: trust-bundle
          extraVolumeMounts:
            - name: ca-certificates
              mountPath: /etc/ssl/certs
              readOnly: true
        ingress:
          hosts:
            - 'borgmon.placeholder.symmatree.com'
          tls:
            - secretName: grafana-tls
              hosts:
                - 'borgmon.placeholder.symmatree.com'
          enabled: true
          ingressClassName: cilium
          annotations:
            cert-manager.io/cluster-issuer: real-cert

        extraObjects:
          - apiVersion: onepassword.com/v1
            kind: OnePasswordItem
            metadata:
              namespace: "argocd-applications"
              name: github-data-source-secret
              labels:
                grafana_datasource: "1"
            type: Opaque
            spec:
              itemPath: "vaults/placeholder/items/grafana-github-token"
          - apiVersion: onepassword.com/v1
            kind: OnePasswordItem
            metadata:
              namespace: "argocd-applications"
              name: grafana-admin-user
            type: Opaque
            spec:
              itemPath: "vaults/placeholder/items/grafana-admin-user"

        # https://github.com/grafana/helm-charts/blob/grafana-8.13.1/charts/grafana/values.yaml
        configMapAnnotations:
          argocd.argoproj.io/sync-options: Replace=true
        persistence:
          enabled: true
        admin:
          existingSecret: grafana-admin-user
          userKey: username
          passwordKey: password
        plugins:
          - grafana-github-datasource
          - grafana-lokiexplore-app
          # - grafana-metricsdrilldown-app
          # - grafana-mqtt-datasource
        initChownData:
          enabled: false
          # Ref https://github.com/grafana/helm-charts/issues/752 for tradeoff
          # between this and outright disabling.
          # This is the user grafana uses, just empirically.
          securityContext:
            runAsUser: 472
            runAsGroup: 472
        sidecar:
          dashboards:
            enabled: true
            searchNamespace: ALL
            folderAnnotation: k8s-sidecar-target-directory
            provider:
              folderUid: sidecar
              folder: Sidecar
              allowUiUpdates: true
              foldersFromFilesStructure: true
          datasources:
            enabled: true
            searchNamespace: ALL

  destination:
    server: https://kubernetes.default.svc
    namespace: grafana
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/warn: baseline
        trust-bundle: enabled
---
# Source: argocd-applications/templates/kubernetes-mixin-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kubernetes-mixin
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: tanka
    plugin:
      env:
        - name: TK_ENV
          value: kubernetes-mixin
      parameters:
        - name: cluster_name
          string: 'placeholder'
        - name: vault_name
          string: 'placeholder'
        - name: project_id
          string: 'placeholder'
        - name: app_settings
          map: {}
  destination:
    server: https://kubernetes.default.svc
    namespace: alloy
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - ServerSideApply=true
---
# Source: argocd-applications/templates/local-path-provisioner-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: local-path-provisioner
spec:
  project: 'placeholder'
  source:
    chart: local-path-provisioner
    repoURL: https://charts.containeroo.ch
    targetRevision: "0.0.32"
    helm:
      valuesObject:
        storageClass:
          create: true
          defaultClass: true
          name: local-path
          reclaimPolicy: Delete
          volumeBindingMode: WaitForFirstConsumer
  destination:
    server: https://kubernetes.default.svc
    namespace: local-path-provisioner
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/enforce: privileged
        pod-security.kubernetes.io/warn: privileged
---
# Source: argocd-applications/templates/loki-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: loki
spec:
  project: 'placeholder'
  source:
    repoURL: "https://grafana.github.io/helm-charts"
    targetRevision: "6.49.0"
    chart: loki
    helm:
      valuesObject:
        vault_name: 'placeholder'
        cluster_name: 'placeholder'
        extraObjects:
          - apiVersion: v1
            kind: ConfigMap
            metadata:
              name: loki-data-source
              namespace: "argocd-applications"
              labels:
                grafana_datasource: "1"
            data:
              datasource.yaml: |-
                apiVersion: 1
                datasources:
                  - name: Loki
                    uid: loki
                    type: loki
                    url: http://loki.loki.svc
                    isDefault: false
                    jsonData:
                      httpHeaderName1: X-Scope-OrgID
                      httpHeaderValue1: "placeholder"
        global:
          extraArgs:
            - -config.expand-env=true
            - -log-config-reverse-order
        loki:
          schemaConfig:
            configs:
              - from: 2024-04-01
                store: tsdb
                object_store: filesystem
                schema: v13
                index:
                  prefix: loki_index_
                  period: 24h
          ingester:
            chunk_encoding: snappy
          pattern_ingester:
            enabled: true
          limits_config:
            volume_enabled: true
          tracing:
            enabled: true
          ruler:
            enable_api: true
          storage:
            type: "filesystem"
          querier:
            # Default is 4, if you have enough memory and CPU you can increase, reduce if OOMing
            max_concurrent: 4

        deploymentMode: SingleBinary
        monitoring:
          dashboards:
            enabled: false
            # annotations:
            #   k8s-sidecar-target-directory: /tmp/dashboards/Loki
          serviceMonitor:
            enabled: true
          rules:
            enabled: false
          selfMonitoring:
            enabled: false

        minio:
          enabled: false

        # Single binary mode configuration
        singleBinary:
          replicas: 1
          enableStatefulSetAutoDeletePVC: true
          persistentVolume:
            storageClass: "nfs-loki"
            size: 100Gi

        gateway:
          replicas: 0
        backend:
          replicas: 0
        read:
          replicas: 0
        write:
          replicas: 0
        chunksCache:
          replicas: 0
        resultsCache:
          replicas: 0
        ingester:
          replicas: 0
        querier:
          replicas: 0
        queryFrontend:
          replicas: 0
        queryScheduler:
          replicas: 0
        distributor:
          replicas: 0
        compactor:
          replicas: 0
        indexGateway:
          replicas: 0
        bloomCompactor:
          replicas: 0
        bloomGateway:
          replicas: 0

  destination:
    server: https://kubernetes.default.svc
    namespace: loki
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/warn: baseline
---
# Source: argocd-applications/templates/mimir-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: mimir
spec:
  project: 'placeholder'
  source:
    repoURL: https://grafana.github.io/helm-charts
    targetRevision: "6.0.5"
    chart: mimir-distributed
    helm:
      valuesObject:
        vault_name: 'placeholder'
        cluster_name: 'placeholder'
        gateway:
          enabled: true
          ingress:
            hosts:
              - 'mimir.placeholder.symmatree.com'
            tls:
              - secretName: mimir-tls
                hosts:
                  - 'mimir.placeholder.symmatree.com'
        extraObjects:
          - apiVersion: v1
            kind: ConfigMap
            metadata:
              name: mimir-data-source
              namespace: "argocd-applications"
              labels:
                grafana_datasource: "1"
            data:
              datasource.yaml: |-
                apiVersion: 1
                datasources:
                  - name: Mimir
                    uid: prom
                    type: prometheus
                    url: http://mimir-gateway.mimir.svc/prometheus
                    isDefault: true
                    jsonData:
                      prometheusType: Mimir
                      alertmanagerUid: alertmanager
                      httpHeaderName1: X-Scope-OrgID
                    secureJsonData:
                      tlsCACert: $__file{/etc/ssl/certs/ca-certificates.crt}
                      httpHeaderValue1: "placeholder"

          - apiVersion: v1
            kind: ConfigMap
            metadata:
              name: alertmanager-data-source
              namespace: "argocd-applications"
              labels:
                grafana_datasource: "1"
            data:
              datasource.yaml: |-
                apiVersion: 1
                datasources:
                  - name: Mimir Alertmanager
                    uid: alertmanager
                    type: alertmanager
                    url: http://mimir-gateway.mimir.svc/
                    jsonData:
                      implementation: mimir
                      handleGrafanaManagedAlerts: true
                      httpHeaderName1: X-Scope-OrgID
                    secureJsonData:
                      httpHeaderValue1: "placeholder"

        global:
          podLabels: {}

        mimir:
          structuredConfig:
            multitenancy_enabled: true
            tenant_federation:
              enabled: true
            common:
              storage:
                backend: filesystem
                filesystem:
                  directory: /mimir/storage
            alertmanager_storage:
              backend: filesystem
            blocks_storage:
              backend: filesystem
            ruler_storage:
              backend: filesystem

        distributor:
          resources:
            requests:
              cpu: null
              memory: 128Mi
        alertmanager:
          zoneAwareReplication:
            enabled: false
          resources:
            requests:
              cpu: null
              memory: 128Mi
          statefulSet:
            enabled: true
          persistentVolume:
            storageClass: "nfs-mimir"
            enableRetentionPolicy: true
            whenDeleted: Delete
            whenScaled: Delete
          terminationGracePeriodSeconds: 60
          extraContainers:
            - name: alert-forward
              # Pull-always since we build daily with security patches.
              imagePullPolicy: Always
              image: "ghcr.io/symmatree/tiles/mimir-webhook:main"
              ports:
                - name: webhook
                  containerPort: 3000
                  protocol: TCP
              env:
                - name: APPRISE_URL
                  # Trailing slash is required
                  value: http://apprise.apprise.svc:8000/notify/
                - name: APPRISE_KEY
                  value: apprise

        compactor:
          persistentVolume:
            storageClass: "nfs-mimir"
            enableRetentionPolicy: true
            whenDeleted: Delete
            whenScaled: Delete
          terminationGracePeriodSeconds: 60

        ingester:
          resources:
            requests:
              cpu: null
              memory: 128Mi
          persistentVolume:
            storageClass: "nfs-mimir"
            enableRetentionPolicy: true
            whenDeleted: Delete
            whenScaled: Delete
          terminationGracePeriodSeconds: 60
          replicas: 2
          zoneAwareReplication:
            enabled: false
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
                - weight: 1
                  podAffinityTerm:
                    labelSelector:
                      matchLabels:
                        app.kubernetes.io/component: ingester
                        app.kubernetes.io/name: mimir
                        app.kubernetes.io/instance: mimir
                    topologyKey: kubernetes.io/hostname
              requiredDuringSchedulingIgnoredDuringExecution: []
        kafka:
          resources:
            requests:
              cpu: null
              memory: 128Mi
        chunks-cache:
          enabled: false
          replicas: 1
          # allocated memory in MB
          allocatedMemory: 512
        index-cache:
          enabled: false
          replicas: 1
          allocatedMemory: 128

        metadata-cache:
          enabled: false
          replicas: 1
          allocatedMemory: 128

        results-cache:
          enabled: false
          replicas: 1
          allocatedMemory: 128

        minio:
          enabled: false

        overrides_exporter:
          replicas: 1
          resources:
            limits:
              memory: 128Mi
            requests:
              cpu: null
              memory: 128Mi

        querier:
          replicas: 1
          resources:
            requests:
              cpu: null
          terminationGracePeriodSeconds: 60
        query_scheduler:
          resources:
            requests:
              cpu: null
              memory: 128Mi
        query_frontend:
          replicas: 1
          resources:
            requests:
              cpu: null
          terminationGracePeriodSeconds: 60

        ruler:
          replicas: 1
          terminationGracePeriodSeconds: 60
          resources:
            requests:
              cpu: null
        store_gateway:
          zoneAwareReplication:
            enabled: false
          resources:
            requests:
              cpu: null
          persistentVolume:
            storageClass: "nfs-mimir"
            enableRetentionPolicy: true
            whenDeleted: Delete
            whenScaled: Delete

  destination:
    server: https://kubernetes.default.svc
    namespace: mimir
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/warn: baseline
---
# Source: argocd-applications/templates/nfs-csi-driver-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: nfs-csi-driver
spec:
  project: 'placeholder'
  source:
    repoURL: https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts
    targetRevision: "4.12.1"
    chart: csi-driver-nfs
    helm:
      valuesObject:
        enableSnapshotter: false
        storageClasses:
          - name: nfs-loki
            parameters:
              server: 'placeholder'
              share: 'placeholder'
            reclaimPolicy: Retain
            volumeBindingMode: Immediate
            mountOptions:
              - uid=placeholder
          - name: nfs-mimir
            parameters:
              server: 'placeholder'
              share: 'placeholder'
            reclaimPolicy: Retain
            volumeBindingMode: Immediate
            mountOptions:
              - uid=placeholder
  destination:
    server: https://kubernetes.default.svc
    namespace: kube-system
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - ServerSideApply=true
---
# Source: argocd-applications/templates/node-exporter-mixin-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: node-exporter-mixin
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: tanka
    plugin:
      env:
        - name: TK_ENV
          value: node-exporter-mixin
      parameters:
        - name: cluster_name
          string: 'placeholder'
        - name: vault_name
          string: 'placeholder'
        - name: project_id
          string: 'placeholder'
        - name: app_settings
          map: {}
  destination:
    server: https://kubernetes.default.svc
    namespace: alloy
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - ServerSideApply=true
---
# Source: argocd-applications/templates/onepassword-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: onepassword
spec:
  project: 'placeholder'
  source:
    repoURL: https://github.com/symmatree/tiles.git
    targetRevision: 'placeholder'
    path: charts/onepassword
    helm:
      valueFiles:
        - values.yaml
  destination:
    server: https://kubernetes.default.svc
    namespace: onepassword
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/warn: baseline
